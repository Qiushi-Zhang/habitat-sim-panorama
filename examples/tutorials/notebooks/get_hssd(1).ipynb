{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pybullet build time: Oct 25 2023 16:25:40\n"
     ]
    }
   ],
   "source": [
    "import habitat_sim\n",
    "import magnum as mn\n",
    "import warnings\n",
    "from habitat.tasks.rearrange.rearrange_sim import RearrangeSim\n",
    "warnings.filterwarnings('ignore')\n",
    "from habitat_sim.utils.settings import make_cfg\n",
    "from matplotlib import pyplot as plt\n",
    "from habitat_sim.utils import viz_utils as vut\n",
    "from omegaconf import DictConfig\n",
    "import numpy as np\n",
    "from habitat.articulated_agents.robots import FetchRobot\n",
    "from habitat.config.default import get_agent_config\n",
    "from habitat.config.default_structured_configs import ThirdRGBSensorConfig, HeadRGBSensorConfig, HeadDepthSensorConfig, HeadPanopticSensorConfig\n",
    "from habitat.config.default_structured_configs import SimulatorConfig, HabitatSimV0Config, AgentConfig\n",
    "from habitat.config.default import get_agent_config\n",
    "import habitat\n",
    "from habitat_sim.physics import JointMotorSettings, MotionType\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from habitat.config.default_structured_configs import HumanoidJointActionConfig, HumanoidPickActionConfig\n",
    "from habitat_llm.agent.env.scene import SceneParser\n",
    "from habitat.config.default_structured_configs import TaskConfig, EnvironmentConfig, DatasetConfig, HabitatConfig\n",
    "from habitat.config.default_structured_configs import ArmActionConfig, BaseVelocityActionConfig, OracleNavActionConfig\n",
    "from habitat.core.env import Env\n",
    "from habitat_llm.perception import Perception\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make simulator\n",
    "def make_sim_cfg(agent_dict):\n",
    "    # Start the scene config\n",
    "    sim_cfg = SimulatorConfig(type=\"RearrangeSim-v0\")\n",
    "    \n",
    "    # This is for better graphics\n",
    "    sim_cfg.habitat_sim_v0.enable_hbao = True\n",
    "    sim_cfg.habitat_sim_v0.enable_physics = True\n",
    "\n",
    "\n",
    "    sim_cfg.additional_object_paths = [\n",
    "        \"data/objects/ycb/configs/\"\n",
    "    ]\n",
    "\n",
    "    \n",
    "    cfg = OmegaConf.create(sim_cfg)\n",
    "\n",
    "    # Set the scene agents\n",
    "    cfg.agents = agent_dict\n",
    "    cfg.agents_order = list(cfg.agents.keys())\n",
    "    return cfg\n",
    "\n",
    "def make_hab_cfg(agent_dict, action_dict):\n",
    "    sim_cfg = make_sim_cfg(agent_dict)\n",
    "    task_cfg = TaskConfig(type=\"RearrangeEmptyTask-v0\")\n",
    "    task_cfg.actions = action_dict\n",
    "    env_cfg = EnvironmentConfig()\n",
    "    dataset_cfg = DatasetConfig(type=\"RearrangeDataset-v0\", data_path=\"data/datasets/hssd_test/hssd_ycb_llm_2.json.gz\")\n",
    "    \n",
    "    \n",
    "    hab_cfg = HabitatConfig()\n",
    "    hab_cfg.environment = env_cfg\n",
    "    hab_cfg.task = task_cfg\n",
    "    hab_cfg.dataset = dataset_cfg\n",
    "    hab_cfg.simulator = sim_cfg\n",
    "    hab_cfg.simulator.seed = hab_cfg.seed\n",
    "\n",
    "    return hab_cfg\n",
    "\n",
    "def init_rearrange_env(agent_dict, action_dict):\n",
    "    hab_cfg = make_hab_cfg(agent_dict, action_dict)\n",
    "    res_cfg = OmegaConf.create(hab_cfg)\n",
    "    return Env(res_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 00:13:57,855 Initializing dataset RearrangeDataset-v0\n",
      "2024-02-12 00:13:57,856 Rearrange task assets are not downloaded locally, downloading and extracting now...\n",
      "2024-02-12 00:13:57,856 Downloaded and extracted the data.\n",
      "2024-02-12 00:13:57,858 initializing sim RearrangeSim-v0\n",
      "[00:14:05:679456]:[Warning]:[Metadata] AttributesManagerBase.h(457)::buildAttrSrcPathsFromJSONAndLoad : <PBR Rendering> : No Glob path result found for `data/fpss/pbr` so unable to load templates from that path.\n",
      "[00:14:07:147344]:[Warning]:[Metadata] SceneDatasetAttributes.cpp(107)::addNewSceneInstanceToDataset : Dataset : 'hssd-hab-articulated-uncluttered' : Lighting Layout Attributes 'data/fpss/scenes-articulated-uncluttered/102817140.scene_instance.json' specified in Scene Attributes but does not exist in dataset, so creating default.\n",
      "[00:14:07:520839]:[Warning]:[Sim] Simulator.cpp(594)::instanceStageForSceneAttributes : The active scene does not contain semantic annotations : activeSemanticSceneID_ = 0\n",
      "2024-02-12 00:14:10,555 Initializing task RearrangeEmptyTask-v0\n",
      "MeshTools::compile(): ignoring unknown/unsupported attribute Trade::MeshAttribute::Custom(0)\n",
      "MeshTools::compile(): ignoring unknown/unsupported attribute Trade::MeshAttribute::Custom(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renderer: Quadro GV100/PCIe/SSE2 by NVIDIA Corporation\n",
      "OpenGL version: 4.6.0 NVIDIA 535.54.03\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_robustness\n",
      "    GL_ARB_texture_storage\n",
      "    GL_ARB_texture_view\n",
      "    GL_ARB_framebuffer_no_attachments\n",
      "    GL_ARB_invalidate_subdata\n",
      "    GL_ARB_texture_storage_multisample\n",
      "    GL_ARB_multi_bind\n",
      "    GL_ARB_direct_state_access\n",
      "    GL_ARB_get_texture_sub_image\n",
      "    GL_ARB_texture_filter_anisotropic\n",
      "    GL_KHR_debug\n",
      "    GL_KHR_parallel_shader_compile\n",
      "    GL_NV_depth_buffer_float\n",
      "Using driver workarounds:\n",
      "    no-forward-compatible-core-context\n",
      "    nv-egl-incorrect-gl11-function-pointers\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    nv-zero-context-profile-mask\n",
      "    nv-implementation-color-read-format-dsa-broken\n",
      "    nv-cubemap-inconsistent-compressed-image-size\n",
      "    nv-cubemap-broken-full-compressed-image-query\n",
      "    nv-compressed-block-size-in-bits\n"
     ]
    }
   ],
   "source": [
    "# Define the agent configuration\n",
    "main_agent_config = AgentConfig()\n",
    "urdf_path = \"data/humanoids/humanoid_data/female_0//female_0.urdf\"\n",
    "main_agent_config.articulated_agent_urdf = urdf_path\n",
    "main_agent_config.articulated_agent_type = \"KinematicHumanoid\"\n",
    "main_agent_config.motion_data_path = \"data/humanoids/humanoid_data/female_0//female_0_motion_data_smplx.pkl\"\n",
    "\n",
    "\n",
    "# Define sensors that will be attached to this agent, here a third_rgb sensor and a head_rgb.\n",
    "# We will later talk about why giving the sensors these names\n",
    "main_agent_config.sim_sensors = {\n",
    "    \"third_rgb\": ThirdRGBSensorConfig(),\n",
    "    \"head_rgb\": HeadRGBSensorConfig(),\n",
    "    \"head_depth\": HeadDepthSensorConfig(normalize_depth=False),\n",
    "    \"head_panoptic\": HeadPanopticSensorConfig(),\n",
    "}\n",
    "\n",
    "# We create a dictionary with names of agents and their corresponding agent configuration\n",
    "agent_dict = {\"main_agent\": main_agent_config}\n",
    "# Define the actions\n",
    "\n",
    "action_dict = {\n",
    "    \"humanoid_joint_action\": HumanoidJointActionConfig()\n",
    "}\n",
    "env = init_rearrange_env(agent_dict, action_dict)\n",
    "_ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pointcloud(obs, cam_matrix):\n",
    "    # Go from depth and rgb and camera params to pointcloud\n",
    "    # plt.figure()\n",
    "    # plt.imshow(obs[\"head_rgb\"])\n",
    "    cam_matrix[1, :] *= -1\n",
    "    cam_matrix[2, :] *= -1\n",
    "    fov = float(env.sim.agents[0]._sensors[\"head_rgb\"].hfov) * np.pi / 180\n",
    "    metric_depth = obs[\"head_depth\"]\n",
    "    height, width = metric_depth.shape\n",
    "    \n",
    "    fs = width / (2* np.tan(fov / 2.))\n",
    "    pointcloud = np.ones((height, width, 4))\n",
    "    depth = metric_depth / fs\n",
    "    pointcloud[:,:,0] = (np.arange(width)[None, ...] - width/2) * depth\n",
    "    pointcloud[:,:,1] = (np.arange(height)[..., None] - height/2) * depth\n",
    "    pointcloud[:,:,2] = -metric_depth\n",
    "\n",
    "    # pointcloud = pointcloud[..., [2,1,0, 3]]\n",
    "    # pointcloud = np.concatenate([pointcloud[..., [2]], pointcloud[..., [1]], pointcloud[..., [0]], pointcloud[..., [3]]], 2)\n",
    "    pco = pointcloud.copy()\n",
    "    \n",
    "    pointcloud = (cam_matrix @ pointcloud.reshape(-1, 4).transpose()).transpose()\n",
    "    pointcloud = pointcloud.reshape(-1, 4)\n",
    "\n",
    "    colors = obs[\"head_rgb\"][:,:,:3].reshape(-1, 3)/255.\n",
    "    # .reshape(height, width, 3)\n",
    "    return pointcloud, colors, pco\n",
    "\n",
    "def to_pointclouds(observations, camera_params):\n",
    "    pcs, cols = [], []\n",
    "    for i in range(len(observations)):\n",
    "        pc, col, pco = to_pointcloud(observations[i], camera_params[i])\n",
    "        pcs.append(pc)\n",
    "        cols.append(col)\n",
    "    return np.concatenate(pcs, 0), np.concatenate(cols, 0), pco\n",
    "\n",
    "\n",
    "env.reset()\n",
    "\n",
    "# Set the initial agent position and rotation\n",
    "env.sim.agents_mgr[0].articulated_agent.base_rot = -np.pi / 2\n",
    "env.sim.agents_mgr[0].articulated_agent.base_pos = mn.Vector3(-3,0,2)\n",
    "\n",
    "# Save all the cameras\n",
    "cameras_all = []\n",
    "observations_all = []\n",
    "current_angle = np.pi\n",
    "\n",
    "# Initial camera transformation\n",
    "init_transform = mn.Matrix4(env.sim.agents[0]._sensors[\"head_rgb\"].node.transformation)\n",
    "for _ in range(10):\n",
    "    env.sim.agents_mgr[0].articulated_agent.base_rot = current_angle\n",
    "    env.sim.agents[0]._sensors[\"head_rgb\"]\n",
    "    current_angle += np.pi/5\n",
    "\n",
    "    env.sim.step({})\n",
    "    observations = env.sim.get_sensor_observations()\n",
    "    observations_all.append(observations)\n",
    "    \n",
    "    agent_node = env.sim._default_agent.scene_node\n",
    "    \n",
    "\n",
    "    cam_trans = np.array(env.sim.agents[0]._sensors[\"head_rgb\"].render_camera.camera_matrix.inverted())\n",
    "\n",
    "    cameras_all.append(cam_trans)\n",
    "\n",
    "pc, colors, pco = to_pointclouds(observations_all, cameras_all)\n",
    "pc = pc[:,:3]\n",
    "\n",
    "import open3d as o3d\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(pc)\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "o3d.io.write_point_cloud(\"./data.ply\", pcd)\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "\n",
    "# fig = plt.figure(figsize=(8, 8))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# print(pc.shape)\n",
    "# stride = 4\n",
    "# ax.scatter(pc[::stride, 0], pc[::stride, 2], pc[::stride, 1], c=colors[::stride])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
